{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Data\n",
    "current_dir = os.getcwd()\n",
    "os.path.join(os.getcwd(), '../data/100.csv')\n",
    "data_100 = pd.read_csv(os.path.join(current_dir, '../data/100.csv'), header=None)\n",
    "data_101 = pd.read_csv(os.path.join(current_dir, '../data/101.csv'), header=None)\n",
    "data_107 = pd.read_csv(os.path.join(current_dir, '../data/107.csv'), header=None)\n",
    "data_201 = pd.read_csv(os.path.join(current_dir, '../data/201.csv'), header=None)\n",
    "data_301 = pd.read_csv(os.path.join(current_dir, '../data/301.csv'), header=None)\n",
    "data_403 = pd.read_csv(os.path.join(current_dir, '../data/403.csv'), header=None)\n",
    "data_404 = pd.read_csv(os.path.join(current_dir, '../data/404.csv'), header=None)\n",
    "data_405 = pd.read_csv(os.path.join(current_dir, '../data/405.csv'), header=None)\n",
    "data_407 = pd.read_csv(os.path.join(current_dir, '../data/407.csv'), header=None)\n",
    "data_413 = pd.read_csv(os.path.join(current_dir, '../data/413.csv'), header=None)\n",
    "\n",
    "\n",
    "# labels\n",
    "labels_100 = pd.read_csv(os.path.join(current_dir, '../labels/100_labels.csv'))\n",
    "labels_101 = pd.read_csv(os.path.join(current_dir, '../labels/101_labels.csv'))\n",
    "labels_107 = pd.read_csv(os.path.join(current_dir, '../labels/107_labels.csv'))\n",
    "labels_201 = pd.read_csv(os.path.join(current_dir, '../labels/201_labels.csv'))\n",
    "labels_301 = pd.read_csv(os.path.join(current_dir, '../labels/301_labels.csv'))\n",
    "labels_403 = pd.read_csv(os.path.join(current_dir, '../labels/403_labels.csv'))\n",
    "labels_404 = pd.read_csv(os.path.join(current_dir, '../labels/404_labels.csv'))\n",
    "labels_405 = pd.read_csv(os.path.join(current_dir, '../labels/405_labels.csv'))\n",
    "labels_407 = pd.read_csv(os.path.join(current_dir, '../labels/407_labels.csv'))\n",
    "labels_413 = pd.read_csv(os.path.join(current_dir, '../labels/413_labels.csv'))\n",
    "\n",
    "# Custom\n",
    "custom_100 = pd.read_csv(os.path.join(current_dir, '../custom/100_custom.csv'))\n",
    "custom_101 = pd.read_csv(os.path.join(current_dir, '../custom/101_custom.csv'))\n",
    "custom_107 = pd.read_csv(os.path.join(current_dir, '../custom/107_custom.csv'))\n",
    "custom_201 = pd.read_csv(os.path.join(current_dir, '../custom/201_custom.csv'))\n",
    "custom_403 = pd.read_csv(os.path.join(current_dir, '../custom/403_custom.csv'))\n",
    "\n",
    "\n",
    "# df name\n",
    "labels_100.name = '100'\n",
    "labels_101.name = '101'\n",
    "labels_107.name = '107'\n",
    "labels_201.name = '201'\n",
    "labels_301.name = '301'\n",
    "labels_403.name = '403'\n",
    "labels_404.name = '404'\n",
    "labels_405.name = '405'\n",
    "labels_407.name = '407'\n",
    "labels_413.name = '413'\n",
    "\n",
    "\n",
    "def resize_heartbeat(heartbeat, size=187):\n",
    "    return heartbeat[:size] if len(heartbeat) >= size else np.pad(heartbeat, (0, size - len(heartbeat)))\n",
    "\n",
    "# Butterworth bandpass\n",
    "def filter_signal(data, low, high, target=256):\n",
    "    fc_low = 2 * low / target  # highpass\n",
    "    fc_high = 2 * high / target  # lowpass\n",
    "\n",
    "    b, a = signal.butter(2, [fc_low, fc_high], btype='bandpass')\n",
    "    # b, a = signal.butter(filter_order, fc_high, btype='low')\n",
    "\n",
    "    # filtfilt applies the same filter twice\n",
    "    filtered_data = signal.filtfilt(b, a, data, axis=0)  # lfilter is phase shifting and for 'online'\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "# Revised dataset\n",
    "def generate_data(custom, labels, input_data):\n",
    "    data = np.concatenate(input_data.to_numpy().tolist())\n",
    "    \n",
    "    datapoint = []\n",
    "\n",
    "    for i in range(len(custom)):\n",
    "        try:\n",
    "            qrs = custom.Samples[i]\n",
    "            qrs_index = labels.loc[labels.Samples == qrs].index[0]\n",
    "            if custom.Label[i] != 'N':\n",
    "                left = int(labels.Samples[qrs_index - 1] + 20)\n",
    "                right = int(labels.Samples[qrs_index + 1])\n",
    "            else:\n",
    "                left = int(labels.Samples[qrs_index] - ((labels.Samples[qrs_index]-labels.Samples[qrs_index - 1])/2.5))\n",
    "                right = int(labels.Samples[qrs_index] + ((labels.Samples[qrs_index + 1]-labels.Samples[qrs_index])/1.5))\n",
    " \n",
    "            heartbeat = data[left:right] * -1\n",
    "            \n",
    "            filtered_heartbeat = filter_signal(heartbeat, 1, 30, 256) # Butterworth filter\n",
    "\n",
    "            normalised_heartbeat = (filtered_heartbeat - filtered_heartbeat.min()) / filtered_heartbeat.ptp() # Normalise signal 0-1\n",
    "            \n",
    "            resampled_heartbeat = signal.resample(normalised_heartbeat, 256)\n",
    "            # resampled_heartbeat = signal.resample(normalised_heartbeat, 125) # Resample to 125Hz\n",
    "\n",
    "            resised_heartbeat = resize_heartbeat(resampled_heartbeat, 187) # Remove or pad signal to size\n",
    "\n",
    "            _data = {'Label': custom.Label[i], 'Form': custom.Form[i], 'Filename': labels.name, 'QRS': qrs,\n",
    "                     'Heartbeat': resised_heartbeat}\n",
    "\n",
    "            datapoint.append(_data)\n",
    "        except:\n",
    "            KeyError\n",
    "\n",
    "    df = pd.DataFrame(datapoint)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Plot data n * m\n",
    "def plot_data(data, n, m):\n",
    "    for i in range(len(data)):\n",
    "        fig, ax = plt.subplots(n, m)\n",
    "        ax = ax.flatten()\n",
    "        x = i * n * m\n",
    "        for j in range(n * m):\n",
    "            ax[j].plot(data.Heartbeat[x + j])\n",
    "            ax[j].set_title(str(data.Label[x + j]) + '|' + str(data['Filename'][x + j] + '|' + str(data['QRS'][x + j])))\n",
    "        # plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "N    2129\n",
      "V       3\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "N    6216\n",
      "V     857\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "S    4821\n",
      "V      10\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "N    22598\n",
      "V     9168\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "V    5871\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "V    24066\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "N    24766\n",
      "V     5947\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "S    1373\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    203 - Keep only N1, N2, N3 = 7620 beats\n",
    "    405 - N1(24771) N3(17120) V2(4824) V3(1123)\n",
    "\"\"\"\n",
    "\n",
    "# Custom\n",
    "df100 = generate_data(custom_100, labels_100, data_100)\n",
    "df101 = generate_data(custom_101, labels_101, data_101)\n",
    "df107 = generate_data(custom_107, labels_107, data_107)\n",
    "df201 = generate_data(custom_201, labels_201, data_201)\n",
    "df403 = generate_data(custom_403, labels_403, data_403)\n",
    "\n",
    "# All\n",
    "df301 = generate_data(labels_301, labels_301, data_301)\n",
    "df404 = generate_data(labels_404, labels_404, data_404)\n",
    "df405 = generate_data(labels_405, labels_405, data_405)\n",
    "df407 = generate_data(labels_407, labels_407, data_407)\n",
    "df413 = generate_data(labels_413, labels_413, data_413)\n",
    "\n",
    "df403n = df403.loc[df403.Label == 'N']\n",
    "df403n = df403n.drop(df403n.loc[df403n.Form != 'N2'].index)\n",
    "df403 = df403.drop(df403.loc[df403.Label == 'N'].index)\n",
    "df403 = pd.concat([df403n, df403])\n",
    "df201 = df201.drop(df201.loc[df201.Label == 'N'].index)\n",
    "df301 = df301.drop(df301.loc[df301.Label == 'N'].index)\n",
    "df404 = df404.drop(df404.loc[df404.Label == 'N'].index)\n",
    "df405 = df405.drop(df405[(df405.Form != 'N1') & (df405.Form != 'V2') & (df405.Form != 'V3')].index)\n",
    "df407 = df407.drop(df407.loc[df407.Label == 'N'].index)\n",
    "df413 = df413.drop(df413.loc[df413.Label == 'N'].index)\n",
    "\n",
    "train = [df101, df107, df301, df403, df407]\n",
    "test = [df404, df405, df413]\n",
    "\n",
    "training = pd.DataFrame(df100)\n",
    "testing = pd.DataFrame(df201)\n",
    "\n",
    "for i in range(len(train)):\n",
    "    print(train[i].Label.value_counts())\n",
    "    # training = training.append(train[i])\n",
    "    training = pd.concat([training, train[i]], ignore_index=True)\n",
    "\n",
    "for i in range(len(test)):\n",
    "    print(test[i].Label.value_counts())\n",
    "    # testing = testing.append(test[i])\n",
    "    testing = pd.concat([testing, test[i]], ignore_index=True)\n",
    "\n",
    "# Remove empty lists\n",
    "training = training[training.Heartbeat.str.len() > 0]\n",
    "testing = testing[testing.Heartbeat.str.len() > 0]\n",
    "\n",
    "# Drop NaN\n",
    "training = training[training['Form'].notna()].reset_index(drop=True)\n",
    "testing = testing[testing['Form'].notna()].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign class labels\n",
    "label_mapping = {'N': 0, 'S': 1, 'V': 2, 'F': 3, 'Q': 4}\n",
    "training['Label'] = training['Label'].map(label_mapping)\n",
    "testing['Label'] = testing['Label'].map(label_mapping)\n",
    "\n",
    "def heartbeat_to_columns(df):\n",
    "    # Extract heartbeat data and convert each to 187 columns\n",
    "    heartbeat_data = np.array(df['Heartbeat'].tolist()) # Convert heartbeat column to array\n",
    "    labels = df['Label'].values\n",
    "    \n",
    "    # Dataframe where each row is a heartbeat\n",
    "    heartbeat_df = pd.DataFrame(heartbeat_data.tolist())\n",
    "    heartbeat_df['Label'] = labels # Add class label to final column\n",
    "    \n",
    "    return heartbeat_df\n",
    "\n",
    "train_final = heartbeat_to_columns(training)\n",
    "test_final = heartbeat_to_columns(testing)\n",
    "\n",
    "# Combine the train and test DataFrames\n",
    "combined_df = pd.concat([train_final, test_final], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined DataFrame\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Calculate the number of rows for training and testing\n",
    "train_size = int(len(combined_df) * 0.8) # 80% for training\n",
    "test_size = len(combined_df) - train_size # 20% for testing\n",
    "\n",
    "# Split the shuffled DataFrame into train and test sets\n",
    "train_split = combined_df[:train_size]\n",
    "test_split = combined_df[train_size:]\n",
    "\n",
    "# Save the train and test dataframes to csv\n",
    "train_split.to_csv('../../train_canine_shuffled.csv', index=False, header=False)\n",
    "test_split.to_csv('../../test_canine_shuffled.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
